
import java.awt.Color;
import java.io.*;
import java.util.ArrayList;
import javax.sound.sampled.*;

import java.text.DecimalFormat;
import java.text.DecimalFormatSymbols;
import java.util.Locale;

import ddf.minim.*;
import ddf.minim.ugens.*;
import net.paulhertz.pixelaudio.*;

/**
 * 
 * WaveSynthSequencer builds on BigWaveSynth and BigWaveSynthAudio, which show how 
 * you can load WaveSynth pixel data into the pixel array of a MultiGen. 
 * WaveSynthSequencer adds some useful features: 
 * 1. you can play the image as a musical sequence, and
 * 2. you can save audio to a .wav file and image to a .png file
 * 
 * This example also allows you to load JSON files to reconfigure the current WaveSynth.
 * You can play any WaveSynth with raindrops ('d' key) or by clicking in the image. 
 * However, the sequencer only plays WaveSynths generated by the buildWaveDataList() method,
 * which generates WaveSynths in the diatonic system of Western music. 
 * Initially, we call buildWaveDataList() to create a WaveData array with eight operators. 
 * The array is passed to a WaveSynth which is further configured by initWaveSynth(). 
 * To load JSON data, press the 'o' key and go to the data folder of this sketch. 
 * 
 * Note that the sampleRate value influences the appearance of the image, the duration
 * of audio samples and the way data is written to an audio file. See BigWaveSynthAudio 
 * example code for documentation of how sampleRate affects audio playback 
 * and WaveSynth patterns. In WaveSynthSequencer, we set the WaveSynth objects sample rate
 * to the global sample rate. This ensures that the musical frequencies are accurate. 
 * 
 * 
 * Press ' ' to start and stop WaveSynth animation.
 * Press 'o' to open a JSON WaveSynth configuration file.
 * Press 'O' to reload the most recent JSON WaveSynth configuration file.
 * Press 'j' or 'J' to save current WaveSynth configuration to a JSON file.
 * Press 's' to save the display to an image file named wavesynth_<wsIndex>.png.
 * Press 'S' to save WaveSynth audio to an audio file named wavesynth_<wsIndex>.wave.
 * Press 'f' to display the current frameRate. 
 * Press 'w' to step the WaveSynth Seqencer without playing a musical note.
 * Press 'W' to step the WaveSynth Seqencer and play the corresponding a musical note.
 * Press 'd' to turn raindrops on or off (raindrops trigger audio events). 
 * Press '\' to run the WaveSynth Sequencer 
 * Press 'c' to reset the image and sound to the opening state. 
 * Press 'h' to show this help message in the console. 
 * 
 */

PixelAudio pixelaudio;      // our shiny new library
HilbertGen hGen;            // a PixelMapGen to draw Hilbert curves
MultiGen multigen;          // a PixelMapGen that handles multiple gens
int rows = 3;               // rows
int columns = 2;            // columns
int genWidth = 512;         // width of PixelMapGen objects, for hGen must be a power of 2
int genHeight = 512;        // height of PixelMapGen objects, for hGen must be equal to width
PixelAudioMapper mapper;    // instance of a class for reading, writing, and transcoding audio and image data 
int mapSize;                // size of the display bitmap, audio signal, wavesynth pixel array, mapper arrays, etc. 
ArrayList<WaveData> wdList;    // a list of audio "operators" that drive a WaveSynth
WaveSynth wavesynth;        // a sort of additive audio synthesis color organ that also produces sound
PImage synthImage;          // local variable that points to wavesynth's PImage instance variable

// WaveSynth variables
float myGamma = 1.0f;       // a non-linear brightness adjustment
int animSteps = 240;        // number of steps in the animation
int animStop = animSteps;   // The step at which the animation should stop (not used here)
int step = 0;               // the current step in the animation
String comments;            // a JSON field that provides information about the WaveSynth effects it produces

/** Minim audio library */
Minim minim;                // library that handles audio 
AudioOutput audioOut;       // line out to sound hardware
MultiChannelBuffer audioBuffer;   // data structure to hold audio samples
boolean isBufferStale = false;    // flags that audioBuffer needs to be reset: i.e., after loading JSON data to wavesynth
int sampleRate = 48000;     // a critical value for display and audio
float[] audioSignal;        // the audio signal as an array of floats
int[] rgbSignal;            // the colors in the display image, in the order the signal path visits them
int audioLength;            // length of the audioSignal, same as the number of pixels in the display image

// SampleInstrument setup
float sampleScale = 4;      // number of divisions of one second of sound, affects duration of audio sample triggered by mouseDown
int sampleBase = (int) (sampleRate/sampleScale);
int samplelen = (int) (sampleScale * sampleBase);
Sampler audioSampler;       // minim class for sampled sound
SamplerInstrument instrument;    // local class to wrap audioSampler

// ADSR and params
ADSR adsr;                  // good old attack, decay, sustain, release
float maxAmplitude = 0.7f;
float attackTime = 0.8f;
float decayTime = 0.5f;
float sustainLevel = 0.125f;
float releaseTime = 0.5f;

// file i/o from JSON
String jsonFolder = "/JSON";
File currentDataFile;
String currentFileName;
JSONObject json;
String daPath;

// animation
boolean isWaveSynthAnimating = true;    // animation status
boolean oldIsAnimating;      // keep old animation status if we suspend animation
boolean isLooping = true;    // looping sample (our instrument ignores this)
boolean isRaining = true;
int circleColor = color(233, 220, 199, 128);

// interaction
int sampleX;
int sampleY;
int samplePos;            // position of a mouse click along the signal path, index into the audio array
ArrayList<TimedLocation> timeLocsArray;
int count = 0;  

/****** WaveSynth Sequencer Settings ******/
/** for frequency calculations, numbers are piano keys */
public static final double semitoneFac = Math.pow(2, 1/12.0);
int[] dbwfMusic = { 
   9, 14, 20,  8,    12, 19,  7, 13,    17, 12, 18, 11,    21, 16, 24, 15,
  26, 24, 19, 25,    24, 17, 11,  4,     9, 14, 20,  8,    12, 19,  7,  9, 
   4,  9, 15,  8,    14, 19, 16, 23,    21, 26, 19, 12,    20, 16, 14, 10
};
/** for time calculations, 12 = one quarter note */
ArrayList<WaveSynth> waveSynthList;
int[] dbwfTimes = {
  12, 12, 12, 12,    8, 4, 12, 24,     12, 12, 18, 6,   4, 4, 16, 24,
  12, 12, 12, 12,    8, 4, 12, 24,     12, 12, 18, 6,   8, 8,  8, 24,
  12, 12, 12, 12,    8, 4, 12, 24,     12, 12, 18, 6,   8, 4, 12, 24
};
/** amplitude values */
float[] dbwfAmps = {
  0.4f, 0.3f, 0.5f, 0.3f,    0.4f, 0.3f, 0.5f, 0.4f,     0.4f, 0.3f, 0.3f, 0.3f,   0.4f, 0.3f, 0.3f, 0.4f,
  0.4f, 0.3f, 0.5f, 0.3f,    0.4f, 0.3f, 0.3f, 0.5f,     0.4f, 0.3f, 0.5f, 0.3f,   0.4f, 0.3f,  0.3f, 0.5f,
  0.4f, 0.3f, 0.3f, 0.3f,    0.4f, 0.3f, 0.3f, 0.4f,     0.4f, 0.3f, 0.5f, 0.3f,   0.4f, 0.3f, 0.3f, 0.5f
};
// beatSpan is measured in milliseconds, where the entire buffer is 32768 ms, divided into 12 * 4 = 48 beats
// Each beat has 12 subdivisions (ticks), so that dbwfTimes[0], which equals 12, is one beat long.
// If we want to run the music in half time, we can set ticks to 6. 
int ticks = 12;
float beatSpan = 32768/(48.0f * ticks); 
int wsIndex = 0;      // index of current WaveSynth
ArrayList<NoteTimedLocation> introMusic;    // Array that captures sequencing data
boolean isPlayIntro = false;  

// number formatting, useful for output to console
DecimalFormat twoPlaces;
DecimalFormat noPlaces;
DecimalFormat fourFrontPlaces;
DecimalFormat commaTwoPlaces;
DecimalFormat eightPlaces;

public void settings() {
  size(rows * genWidth, columns * genHeight);
}

public void setup() {
  frameRate(30);
  pixelaudio = new PixelAudio(this);
  minim = new Minim(this);
  sampleRate = 48000;               // the animation uses sampleRate = 48000 for its symmetry effects
  sampleBase = sampleRate / 4;      // a quarter of a second
  initAudio();                      // set up audio output and an audio buffer
  multigen = loadLoopGen(genWidth, genHeight);  // See the MultiGenDemo example for details on how MultiGen works
  mapper = new PixelAudioMapper(multigen);    // initialize a PixelAudioMapper
  float drone = sampleRate/1024.0f;           // a frequency that generates visual symmetries
  wdList = buildWaveDataList(drone, 8, 10);   // generate a WaveData list for the WaveSynth
  wavesynth = new WaveSynth(mapper, wdList);  // initialize a WaveSynth object
  initWaveSynth(wavesynth);                   // fill in some parameters of the WaveSynth
  synthImage = wavesynth.mapImage;            // point synthImage at the WaveSynth's PImage field
  mapSize = mapper.getSize();                 // size of the image, and of various other entities
  timeLocsArray = new ArrayList<TimedLocation>();     // initialize mouse event tracking array
  initDecimalFormats();             // initializes some utility functions for formatting numbers
  initWaveSynthList();              // sets up a sequencer using dbwfMusic, dbwfTimes, and dbwfAmps arrays
  // path to the folder where PixelAudio examples keep their data files 
  // such as image, audio, .json, etc.
  daPath = sketchPath("") + "../examples_data";
  println("daPath: ", daPath);
  showHelp();
}

public void initAudio() {
  // use the getLineOut method of the Minim object to get an AudioOutput object
  this.audioOut = minim.getLineOut(Minim.MONO, 1024, sampleRate);
  this.audioBuffer = new MultiChannelBuffer(1024, 1);
  // ADSR envelope with maximum amplitude, attack Time, decay time, sustain level, and release time
  adsr = new ADSR(maxAmplitude, attackTime, decayTime, sustainLevel, releaseTime);
}

/**
 * Adds PixelMapGen objects to the local variable genList, puts the coords
 * of their upper left corner in offsetList. The two lists are used to  
 * initialize a MultiGen, which can be used to map audio and pixel data.
 * This method provides a big looping fractal consisting of 6 Hilbert curves.
 */
public MultiGen loadLoopGen(int loopGenW, int loopGenH) {
  // list of PixelMapGens that create an image using mapper
  ArrayList<PixelMapGen> genList = new ArrayList<PixelMapGen>(); 
  // list of x,y coordinates for placing gens from genList
  ArrayList<int[]> offsetList = new ArrayList<int[]>();     
  genList.add(new HilbertGen(loopGenW, loopGenH, AffineTransformType.FLIPX90));
  offsetList.add(new int[] { 0, 0 });
  genList.add(new HilbertGen(loopGenW, loopGenH, AffineTransformType.NADA));
  offsetList.add(new int[] { loopGenW, 0 });
  genList.add(new HilbertGen(loopGenW, loopGenH, AffineTransformType.FLIPX90CCW));
  offsetList.add(new int[] { 2 * loopGenW, 0 });
  genList.add(new HilbertGen(loopGenW, loopGenH, AffineTransformType.FLIPX90CCW));
  offsetList.add(new int[] { 2 * loopGenW, loopGenH });
  genList.add(new HilbertGen(loopGenW, loopGenH, AffineTransformType.ROT180));
  offsetList.add(new int[] { loopGenW, loopGenH });
  genList.add(new HilbertGen(loopGenW, loopGenH, AffineTransformType.FLIPX90));
  offsetList.add(new int[] { 0, loopGenH });
  return new MultiGen(width, height, offsetList, genList);
}

/**
 * Initializes number formatters, handy for display.
 */
public void initDecimalFormats() {
  // DecimalFormat sets formatting conventions from the local system, unless we tell it otherwise.
  // make sure we use "." for decimal separator, as in US, not a comma, as in many other countries
  Locale loc = Locale.US;
  DecimalFormatSymbols dfSymbols = new DecimalFormatSymbols(loc);
  dfSymbols.setDecimalSeparator('.');
  twoPlaces = new DecimalFormat("0.00", dfSymbols);
  noPlaces = new DecimalFormat("00", dfSymbols);
  fourFrontPlaces = new DecimalFormat("0000", dfSymbols);
  eightPlaces = new DecimalFormat("0.00000000", dfSymbols);
  dfSymbols.setDecimalSeparator(',');
  commaTwoPlaces = new DecimalFormat("0.00", dfSymbols);
}

/**
 * The main loop for drawing to the screen.
 */
public void draw() {
  image(synthImage, 0, 0, width, height);     // draw the synth image
  if (isWaveSynthAnimating) stepAnimation();  // animate the image if requested
  runTimeArray();                             // animate audio event markers
  if (isPlayIntro && introMusic.size() > 0) {
    runMusicArray();                          // play the WaveSynth Sequencer
  }
  if (isRaining) {
    // animation slows the frame rate, so we change the threshold when animating
      float thresh = (isWaveSynthAnimating) ? 0.25f : 0.05f;
      if (random(0,1) < thresh) {
        raindrops();                          // trigger random audio events
      }
  }
}

/**
 * Animates the WaveSynth referenced by variable wavesynth.
 * The animation is controlled by the WaveSynth phase and cycle attributes.
 */
public void stepAnimation() {
  step += 1;
  step %= animSteps;
  wavesynth.renderFrame(step);
}

/**
 * Run the animation for audio events. 
 */
public void runTimeArray() {
  int currentTime = millis();
  timeLocsArray.forEach(tl -> {
    tl.setStale(tl.stopTime() < currentTime);
    if (!tl.isStale()) {
      drawCircle(tl.getX(), tl.getY());
    }
  });
  timeLocsArray.removeIf(TimedLocation::isStale);
}

/**
 * Run the WaveSynth Sequencer.
 */
public void runMusicArray() {
  int currentTime = millis();
  introMusic.forEach(tl -> {
    if (tl.stopTime() < currentTime) {
      isWaveSynthAnimating = false;
      wavesynth = tl.getWaveSynth();
      wavesynth.prepareAnimation();
      wavesynth.renderFrame(0);
      synthImage = wavesynth.mapImage;
      renderSignal();
      int len = (int) ((48 * tl.duration) * 0.4f);
      sampleX = tl.getX();
      sampleY = tl.getY();
      circleColor = tl.getCircleColor();
      // println("---> music ", tl.getX(), tl.getY(), mapper.lookupSample(tl.getX(), tl.getY()));
      // println("---> music ", twoPlaces.format(tl.getAmplitude()));
      playSample(mapper.lookupSample(tl.getX(), tl.getY()), len, tl.getAmplitude(), tl.getAdsr());
      tl.setStale(true);
    }
    else {
      return;
    }
  });
  introMusic.removeIf(NoteTimedLocation::isStale);
}

/**
 * Draws a circle at the location of an audio trigger (mouseDown event).
 * @param x    x coordinate of circle
 * @param y    y coordinate of circle
 */
public void drawCircle(int x, int y) {
  float size = isRaining? random(10, 30) : 60;
  fill(circleColor);
  noStroke();
  circle(x, y, size);
}  

/**
 * Trigger a WaveSynth sample at a random location.
 */
public void raindrops() {
  int signalPos = (int) random(samplelen, mapSize - samplelen - 1);
  int[] coords = mapper.lookupCoordinate(signalPos);
  sampleX = coords[0];
  sampleY = coords[1];
  if (audioSignal == null || isBufferStale) {
    renderSignal();
    isBufferStale = false;
  }
  playSample(signalPos, samplelen, 0.15f, new ADSR(maxAmplitude, attackTime, decayTime, sustainLevel, releaseTime));  
}

public void keyPressed() {
  switch (key) {
  case ' ':
    isWaveSynthAnimating = !isWaveSynthAnimating;
    println(isWaveSynthAnimating ? "Starting animation at frame " + step + " of " + animSteps
        : "Stopping animation at frame " + step + " of " + animSteps);
    break;
  case 'o':
    // turn off animation while reading new settings for wavesynth
    oldIsAnimating = isWaveSynthAnimating;
    isWaveSynthAnimating = false;
    this.loadWaveData();
    isBufferStale = true;
    break;
  case 'O':
    if (currentDataFile == null) {
      loadWaveData();
    } 
    else {
      fileSelectedOpen(currentDataFile);
      println("-------->>>>> Reloaded file");
    }
    break;
  case 'j':
  case 'J':
    saveWaveData();
    break;
  case 's': 
    String fName = "wavesynth_"+ wsIndex +".png";
    synthImage.save(fName);
    println("--- saved image "+ fName);
    break;
  case 'S': 
    saveToAudio();
    break;
  case 'f':
    println("--->> frame rate: "+ frameRate);
    break;
  case 'w':
    stepWaveSynth();
    break;
  case 'W':
    stepWaveSynth();
    playSample(mapper.lookupSample(width/2, height/2), calcSampleLen(), 0.3f, new ADSR(maxAmplitude, attackTime, decayTime, sustainLevel, releaseTime));
    break;
  case 'd':
    isRaining = !isRaining;
    println("----->>> isRaining ", isRaining);
    break;
  case '\\':
    isRaining = false;
    loadMusic();
    isPlayIntro = true;
    break;
  case 'c':
    wavesynth = new WaveSynth(mapper, wdList);
    initWaveSynth(wavesynth);
    wavesynth.prepareAnimation();
    wavesynth.renderFrame(0);
    this.synthImage = wavesynth.mapImage;
    renderSignal();
    isWaveSynthAnimating = true;
    break;
  case 'h':
    showHelp();
    break;
  default:
    break;
  }
}

/**
 * Advance the WaveSynth Sequencer to its next state. 
 */
public void stepWaveSynth() {
  wavesynth = this.waveSynthList.get(wsIndex);
  wavesynth.prepareAnimation();
  wavesynth.renderFrame(0);
  synthImage = wavesynth.mapImage;  // point synthImage at the WaveSynth's PImage field
  renderSignal();            // copy wavesynth audio to audio buffer
  wsIndex++;
  if (wsIndex > waveSynthList.size() - 1) wsIndex = 0;
}

public void showHelp() {
  println(" * Press ' ' to start and stop WaveSynth animation.");
  println(" * Press 'o' to open a JSON WaveSynth configuration file.");
  println(" * Press 'O' to reload the most recent JSON WaveSynth configuration file.");
  println(" * Press 'j' or 'J' to save current WaveSynth configuration to a JSON file.");
  println(" * Press 's' to save the display to an image file named wavesynth_<wsIndex>.png."); 
  println(" * Press 'S' to save WaveSynth audio to an audio file named wavesynth_<wsIndex>.wav."); 
  println(" * Press 'f' to display the current frameRate. ");
  println(" * Press 'w' to step the WaveSynth Seqencer without playing a musical note.");
  println(" * Press 'W' to step the WaveSynth Seqencer and play the corresponding a musical note.");
  println(" * Press 'd' to turn raindrops on or off (raindrops trigger audio events). ");
  println(" * Press '\\' to run the WaveSynth Sequencer ");
  println(" * Press 'c' to reset the image and sound to the opening state. ");
  println(" * Press 'h' to show this help message in the console. ");
}

/**
 * Save audio buffer to a file called "wavesynth_<wsIndex>.wav".
 */
public void saveToAudio() {
  renderSignal();
  try {
    saveAudioToFile(audioSignal, sampleRate, "wavesynth_"+ wsIndex +".wav");
  }
  catch (IOException e) {
    println("--->> There was an error outputting the audio file wavesynth.wav "+ e.getMessage());
  }
  catch (UnsupportedAudioFileException e) {
    println("--->> The file format is unsupported "+ e.getMessage());
  }
}

/**
 * Calls WaveSynth to render a audio sample array derived from the same math that creates the image.
 */
public void renderSignal() {
  this.audioSignal = wavesynth.renderAudioRaw(step);      // get the signal "as is" from WaveSynth
  audioSignal = WaveSynth.normalize(audioSignal, 0.9f);    // normalize samples to the range (-0.9f, 0.9f) 
  audioLength = audioSignal.length;
  audioBuffer.setBufferSize(audioLength);
  audioBuffer.setChannel(0, audioSignal);            // copy audioSignal to channel 0 of audioBuffer
  // println("--->> copied audio signal to audio buffer");
}

public void mousePressed() {
  sampleX = mouseX;
  sampleY = mouseY;
  samplePos = mapper.lookupSample(sampleX, sampleY);
  if (audioSignal == null || isBufferStale) {
    renderSignal();
    isBufferStale = false;
  }
  playSample(samplePos, calcSampleLen(), 0.3f, new ADSR(maxAmplitude, attackTime, decayTime, sustainLevel, releaseTime));
}

/**
 * @param samplePos    position of the sample in the audio buffer
 * @param samplelen    length of the sample (will be adjusted)
 * @param amplitude    amplitude of the sample on playback
 * @param adsr      an ADSR envelope for the sample
 * @return        the calculated sample length in samples
 */
public int playSample(int samplePos, int samplelen, float amplitude, ADSR adsr) {
  // println("--- play "+ twoPlaces.format(amplitude));
  // create a Minim Sampler from the buffer, with sampleRate sampling rate, 
  // for up to 8 simultaneous outputs
  audioSampler = new Sampler(audioBuffer, sampleRate, 8);
  // set amplitude for the Sampler
  audioSampler.amplitude.setLastValue(amplitude);
  // set the Sampler to begin playback at samplePos, which corresponds 
  // to the place the mouse was clicked
  audioSampler.begin.setLastValue(samplePos);
  // do some calculation to include the release time.
  int releaseDuration = (int) (releaseTime * sampleRate); 
  if (samplePos + samplelen >= mapSize) {
    // make sure we don't exceed the mapSize
    samplelen = mapSize - samplePos; 
    println("----->>> sample length = " + samplelen);
  }
  int durationPlusRelease = this.samplelen + releaseDuration;
  int end = (samplePos + durationPlusRelease >= this.mapSize) ? this.mapSize - 1
      : samplePos + durationPlusRelease;
  // println("----->>> end = " + end);
  audioSampler.end.setLastValue(end);
  this.instrument = new SamplerInstrument(audioSampler, adsr);
  // play command takes a duration in seconds
  float duration = samplelen / (float) (sampleRate);
  instrument.play(duration);
  timeLocsArray.add(new TimedLocation(sampleX, sampleY, (int) (duration * 1000) + millis()));
  // return the length of the sample
  return samplelen;
}

public int calcSampleLen() {
  float vary = (float) (PixelAudio.gauss(this.sampleScale, this.sampleScale * 0.125f)); // vary the duration of the signal 
  // println("----->>> vary = "+ vary +", sampleScale = "+ sampleScale);
  this.samplelen = (int) (vary * this.sampleBase); // calculate the duration of the sample
  return samplelen;
}


// ------------------------------------------- //
//            FREQUENCY CALCULATIONS           //
// ------------------------------------------- //

/**
 * Generates an ArrayList of WaveData objects to be used by a WaveSynth to
 * generate RGB pixel values and (on request) audio signal values.
 * A version of this code is included in the WaveSynthBuilder class in the PixelAudio library, 
 * wrapped in a static method called synthTrumpet(float fundamental, int howManyPartials, float pianoKey, int animSteps). 
 *
 * @return an ArrayList of WaveData objects
 */
public ArrayList<WaveData> buildWaveDataList(float fundamental, int howManyPartials, float pianoKey) {
  ArrayList<WaveData> list = new ArrayList<WaveData>();
  if (howManyPartials < 1)
    howManyPartials = 1;
  // funda is the fundamental of a musical tone that is somewhat like a trumpet
  // in its frequency spectrum. Vary it to see how the image and sound change.
  float funda = fundamental;
  float frequency = funda;
  float amplitude = 0.55f;
  float phase = 0.766f;
  float dc = 0.0f;
  float cycles = -8.0f;
  int waveColor = color(0, 89, 233);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  int steps = this.animSteps;
  WaveData wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 1)
    return list;
  frequency = 2 * funda;
  amplitude = 0.52f;
  phase = -0.89f;
  cycles = 8.0f;
  waveColor = color(89, 199, 55);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 2)
    return list;
  frequency = 3 * funda;
  amplitude = 0.6f;
  phase = -0.486f;
  cycles = 3.0f;
  waveColor = color(254, 89, 110);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 3)
    return list;
  frequency = 4 * funda;
  amplitude = 0.45f;
  phase = -0.18616974f;
  cycles = -2.0f;
  waveColor = color(89, 110, 233);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 4)
    return list;
  frequency = 5 * funda;
  amplitude = 0.42f;
  phase = 0.6846085f;
  cycles = -5.0f;
  waveColor = color(233, 34, 21);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 5)
    return list;
  frequency = 6 * funda;
  amplitude = 0.45f;
  phase = 0.68912f;
  cycles = 13.0f;
  waveColor = color(220, 199, 55);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 6)
    return list;
  frequency = 7 * funda;
  amplitude = 0.25f;
  phase = 0.68f;
  cycles = 11.0f;
  waveColor = color(159, 190, 255);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  //
  if (howManyPartials == 7)
    return list;
  frequency = 8 * funda;
  amplitude = 0.32f;
  phase = 0.68f;
  cycles = -11.0f;
  waveColor = color(209, 178, 117);
  waveColor = colorShift(waveColor, (pianoKey % 12) / 12.0f);
  wd = new WaveData(frequency, amplitude, phase, dc, cycles, waveColor, steps);
  list.add(wd);
  return list;
}

/**
 * @param c      an RGB color 
 * @param shift    the shift [0..1] of the hue in the HSB representation of color c
 * @return      the RGB representation of the shifted color
 */
public int colorShift(int c, float shift) {
  float[] hsb = new float[3];
  float h = PixelAudioMapper.hue(c, hsb);
  h = (h + shift);
  return Color.HSBtoRGB(h, hsb[1], hsb[2]);
}

/**
 * Sets instance variables for a supplied WaveSynth.
 * @param synth
 * @return
 */
public WaveSynth initWaveSynth(WaveSynth synth) {
  synth.setGain(0.44f);
  synth.setGamma(myGamma);
  synth.setScaleHisto(false);
  synth.setAnimSteps(this.animSteps);
  synth.setSampleRate(sampleRate);
  // synth.setNoiseiness(0.5f);
  // println("--- mapImage size = " + synth.mapImage.pixels.length);
  synth.prepareAnimation();
  // synth.renderFrame(0);
  return synth;
}

/**
 * @param keyNumber key number on a piano, where A440 is key 49
 * @return          frequency of the key (A = 440)
 */
public float pianoKeyFrequency(int keyNumber) {
  return (float) (440 * Math.pow(2, (keyNumber - 49) / 12.0));
}

/**
 * @param funda   the starting frequency
 * @return      a chromatic scale starting with funda
 */
public float[] chromaticScale(float funda) {
  float[] chromaScale = new float[12];
  for (int i = 0; i < chromaScale.length; i++) {
    chromaScale[i] = funda;
    funda *= (float) semitoneFac;
  }
  return chromaScale;
}

/**
 * Initializes a list of WaveSynth objects using pianoKey numbers in dbwfMusic array.
 */
public void initWaveSynthList() {
  this.waveSynthList = new ArrayList<WaveSynth>();
  for (int pianoKey : this.dbwfMusic) {
    float f = pianoKeyFrequency(pianoKey);
    WaveSynth ws = new WaveSynth(mapper, this.buildWaveDataList(f, 8, pianoKey));
    initWaveSynth(ws);
    waveSynthList.add(ws);      
  }
}

/**
 * Initializes the introMusic ArrayList of NoteTimedLocation objects, data for a simple audio sequencer. 
 * Uses the dbwfTimes array to set durations, dbwfMusic to set frequencies, and dbwfAmps to set amplitudes.
 */
public void loadMusic() {
  if (introMusic == null)
    introMusic = new ArrayList<NoteTimedLocation>();
  this.introMusic.clear();
  int startTime = millis() + 500;
  int i = 0;
  int stopSum = startTime;
  int circ = 0;
  int signalPos;
  int[] coords;
  int x;
  int y;
  float span;
  ADSR adsr = new ADSR(maxAmplitude, attackTime, decayTime, sustainLevel, releaseTime, 0, 0);
  println("\n----- SEQUENCER DATA -----\n   piano key, frequency, duration, stop time ms");
  for (int dur : this.dbwfTimes) {
    signalPos = (int) random(samplelen, mapSize - samplelen - 1);
    coords = mapper.lookupCoordinate(signalPos);
    x = coords[0];
    y = coords[1];
    circ = color(233, 220, 199, 128);
    adsr = new ADSR(maxAmplitude, attackTime, decayTime, sustainLevel, releaseTime, 0, 0);
    span = dur * this.beatSpan;
    int pianoKey = this.dbwfMusic[i];
    float f = 1.0f * pianoKeyFrequency(pianoKey);
    WaveSynth ws = new WaveSynth(mapper, this.buildWaveDataList(f, 8, pianoKey));
    initWaveSynth(ws);
    float amp = dbwfAmps[i];
    introMusic.add(new NoteTimedLocation(x, y, stopSum, i, pianoKey, span, amp * 1.8f, circ, adsr, ws));
    i++;
    stopSum += (int) (Math.round(span));
    println("  ", pianoKey, twoPlaces.format(f), twoPlaces.format(span), stopSum);
  }
}  
